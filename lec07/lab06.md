Jupyter Notebook
lab06.md
10.05.2023
Markdown
File
Edit
View
Language

# Практическая лабараторная работа 6

Подбор наилучших параметров модели на сетке. Ансамбли моделей.

## Цель

* Знакомство с методами улучшения моделей путем подбора их параметров.


## Порядок выполнения работы


#### 1. Загрузить любой набор данных с https://www.kaggle.com, подходящий к задачам классификации и регрессии (либо два набора - отдельно для каждой из задач).

    * Набор данных должен содержать минимум 4 независимых числовых и 1 зависимый номинальный признак - для задачи классификации, и 1 числовой - для задачи регрессии
	* Допустимо найти два разных набора данных отдельно для задачи регрессии и отдельно для задачи классификации


#### 2. Выполнить подбор параметров модели классификатора и регрессора (по выбору) с использованием GridSearchCV:

    1. Выбрать какую-нибудь модель классификатора (KNeighborsClassifier, DecisionTreeClassifier, Наивный Байес, LogisticRegression...):

        1.1. Выбрать совокупность настраиваемых параметров и диапазоны их значений

        1.2. Реализовать поиск наилучших параметров с использованием GridSearchCV

        1.3. Вывести наилучшие найденные значения параметров и соответствующую метрику качества классификации
        
		
	2. Выбрать какую-нибудь модель регрессора (KNeighborsRegressor, DecisionTreeRegressor, LinearReegresion, ...):
		        
		2.1. Выбрать совокупность настраиваемых параметров и диапазоны их значений

        2.2. Реализовать поиск наилучших параметров с использованием GridSearchCV

        2.3. Вывести наилучшие найденные значения параметров и соответствующую метрику качества модели
		
	3. При запуске перебора значений на сетке (полный перебор) полезно использовать опцию параллельных вычислений *n_jobs* (количество параллельных процессов). Значение -1 задействует все вычислительные ядра ЦП.  


#### 3. Решить задачу классификации с использованием случайного леса (RandomForestClassifier):

	1. С помощью GridSearchCV подобрать наилучшие параметры случайного леса для задачи классификации 

	2. С полученными параметрами вычислить метрики качества классификации (Confusion Matrix, ROC + AUC)


#### 4. Реализовать ансамбли моделей для задачи классификации и регрессии 

	1. Реализовать бэггинг BaggingClassifier на базе любой модели классификации
	
	2. Реализовать бэггинг для задачи регрессии BaggingRegressor для любой модели регрессии
        
    3. Реализовать меод градиентного бустинга GradiendBoostingClassifier на базе любой модели классификации 
	
	4. Реализовать меод градиентного бустинга GradiendBoostingRegressor на базе любой модели регрессии 
	
	5. Для всех методов вывести метрики качества моделей
		
	
### **Результат выполнения работы должен быть отражен в тетради (notebook) Jupyter с текстовыми вставками пояснений и комментариев**


[как создать окружение?](https://github.com/Letch49/ML_VVSU_2023/blob/main/make_env.md)


